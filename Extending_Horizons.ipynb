{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the file path\n",
    "file_path_train = \"measurements_by_patient_train.pkl\"\n",
    "file_path_test = \"measurements_by_patient_test.pkl\"\n",
    "\n",
    "with open(file_path_train, 'rb') as file:\n",
    "    train = pickle.load(file)\n",
    "\n",
    "with open(file_path_test, 'rb') as file:\n",
    "    test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating windows\n",
    "\n",
    "This section create the windows for the new two horizons (90 and 120 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_windows_one_step_walk_forward(data, lookback_samples, pred_samples):\n",
    "  \"\"\"\n",
    "\n",
    "    :param data:\n",
    "    :param lookback_samples: Number of samples used to predict\n",
    "    :param pred_samples: Prediction window (normally 30 or 60 minutes)\n",
    "    :param backup: Save the progress each 100 patients\n",
    "    :return: Get windows without missing values from one step sliding windows\n",
    "    \"\"\"\n",
    "  x_per_patient = []\n",
    "  y_per_patient = []\n",
    "\n",
    "  for data_patient in data:\n",
    "\n",
    "    # Creating the one step sliding window\n",
    "    x = np.lib.stride_tricks.sliding_window_view(data_patient[:-pred_samples], lookback_samples)\n",
    "    y = np.lib.stride_tricks.sliding_window_view(data_patient[lookback_samples:], pred_samples)\n",
    "\n",
    "    # Removing rows with missing values\n",
    "    nan_rows_x = np.isnan(x).any(axis=1)\n",
    "    nan_rows_y = np.isnan(y).any(axis=1)\n",
    "    x = x[~(nan_rows_x | nan_rows_y)]\n",
    "    y = y[~(nan_rows_x | nan_rows_y)]\n",
    "\n",
    "    x_per_patient.append(x)\n",
    "    y_per_patient.append(y)\n",
    "\n",
    "  x_result = np.concatenate(x_per_patient)\n",
    "  y_result = np.concatenate(y_per_patient)\n",
    "\n",
    "  return x_result, y_result\n",
    "\n",
    "\n",
    "\n",
    "history_length = 8\n",
    "horizons = [6, 8] #90 and 120 min\n",
    "\n",
    "for hor in horizons:\n",
    "    x_train, y_train = get_windows_one_step_walk_forward(train.values(), history_length, hor)\n",
    "    x_test, y_test = get_windows_one_step_walk_forward(test.values(), history_length, hor)\n",
    "    # NOTE: Replace with your filepath\n",
    "    np.save('windows/x_train_windows_horizon_{0}.npy'.format(hor), x_train)     \n",
    "    np.save('windows/y_train_windows_horizon_{0}.npy'.format(hor), y_train)\n",
    "    np.save('windows/x_test_windows_horizon_{0}.npy'.format(hor), x_test)\n",
    "    np.save('windows/y_test_windows_horizon_{0}.npy'.format(hor), y_test)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliar Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def read_windows(horizon):\n",
    "  file_x_train = f\"windows/x_train_windows_horizon_{horizon}.npy\"\n",
    "  file_y_train = f\"windows/y_train_windows_horizon_{horizon}.npy\"\n",
    "  file_x_test  = f\"windows/x_test_windows_horizon_{horizon}.npy\"\n",
    "  file_y_test  = f\"windows/y_test_windows_horizon_{horizon}.npy\"\n",
    "  \n",
    "  print(f\"Reading training files {file_x_train} and {file_y_train}...\")\n",
    "  print(f\"Reading test files {file_x_test} and {file_y_test}...\")\n",
    "  \n",
    "  x_train = np.load(file_x_train)\n",
    "  y_train = np.load(file_y_train)\n",
    "  x_test = np.load(file_x_test)\n",
    "  y_test = np.load(file_y_test)\n",
    "\n",
    "  # Using only the horizon measurement as a label\n",
    "  y_train = y_train[:, -1]\n",
    "  y_train = y_train.reshape((y_train.shape[0], 1))\n",
    "  y_test = y_test[:, -1]\n",
    "  y_test = y_test.reshape((y_test.shape[0], 1))\n",
    "\n",
    "  return x_train, y_train, x_test, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM and linear model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, LSTM, GRU, Lambda, dot, concatenate, Activation, Input\n",
    "\n",
    "# LSTM\n",
    "class LSTMModel:\n",
    "    def __init__(self, input_shape, nb_output_units, nb_hidden_units=128):\n",
    "        self.input_shape = input_shape\n",
    "        self.nb_output_units = nb_output_units\n",
    "        self.nb_hidden_units = nb_hidden_units\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return 'LSTM_{0}_units_{1}_layers_dropout={2}_{3}'.format(self.nb_hidden_units, self.nb_layers, self.dropout, self.recurrent_dropout)\n",
    "    \n",
    "    def build(self):\n",
    "        # input\n",
    "        i = Input(shape=self.input_shape)\n",
    "\n",
    "        # add LSTM layer\n",
    "        x = LSTM(self.nb_hidden_units)(i)\n",
    "\n",
    "        x = Dense(self.nb_output_units, activation=None)(x)\n",
    "\n",
    "        return Model(inputs=[i], outputs=[x])\n",
    "    \n",
    "# Linear\n",
    "class LinearModel:\n",
    "    def __init__(self, input_shape, nb_output_units):\n",
    "        self.input_shape = input_shape\n",
    "        self.nb_output_units = nb_output_units\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Linear'\n",
    "\n",
    "    def build(self):\n",
    "        i = Input(shape=self.input_shape)\n",
    "        x = Dense(self.nb_output_units, activation=None)(i)\n",
    "\n",
    "        return Model(inputs=[i], outputs=[x])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import keras.backend as K\n",
    "from tensorflow import keras\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "\n",
    "#def RMSE(output, target):\n",
    "#    output = K.cast(output, 'float32')\n",
    "#    target = K.cast(target, 'float32')\n",
    "#\n",
    "#    return K.sqrt(K.mean((output - target) ** 2))\n",
    "\n",
    "def build_model(model, weights=''):\n",
    "  \n",
    "  # build & compile model\n",
    "  m = model.build()\n",
    "\n",
    "  m.compile(loss=RootMeanSquaredError,\n",
    "            optimizer=keras.optimizers.legacy.Adam(),\n",
    "            metrics=[RootMeanSquaredError])\n",
    "  if weights:\n",
    "    print(f\"Weights: {weights}\")\n",
    "    m.load_weights(weights)\n",
    "  return m\n",
    "\n",
    "def callbacks(filepath, early_stopping_patience):\n",
    "  callbacks = []\n",
    "  callbacks.append(ModelCheckpoint(filepath=filepath,\n",
    "                                  monitor='RMSE',\n",
    "                                  save_best_only=True,\n",
    "                                  save_weights_only=True))\n",
    "  callbacks.append(EarlyStopping(monitor='RMSE', patience=early_stopping_patience))\n",
    "  return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def prepare_model_LSTM(history_length, nb_hidden_units=128, weights=''):\n",
    "  model = LSTMModel(input_shape=(history_length, 1), nb_output_units=1, nb_hidden_units=nb_hidden_units)\n",
    "  return build_model(model, weights)\n",
    "\n",
    "def prepare_model_linear(history_length, weights=''):\n",
    "  model = LinearModel(input_shape=(history_length,), nb_output_units=1)\n",
    "  return build_model(model, weights)\n",
    " \n",
    " \n",
    " \n",
    "def train(x_train, y_train, model, horizon, save_filepath = \"\", early_stopping_patience=50):\n",
    "\n",
    "  history_length = 8\n",
    "  x_train = np.reshape(x_train, (x_train.shape[0], history_length, 1))\n",
    "\n",
    "  hist = model.fit(x_train, y_train,\n",
    "                batch_size=32,\n",
    "                epochs=500,\n",
    "                #shuffle=True,\n",
    "                callbacks=callbacks(save_filepath + str(horizon), \n",
    "                                    early_stopping_patience)\n",
    "                )\n",
    "\n",
    "\n",
    "  return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "In this sections the models are trained for the new horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_length = 8 # 2h\n",
    "\n",
    "x_train_6, y_train_6, x_test_6, y_test_6 = read_windows(horizon=6)\n",
    "x_train_8, y_train_8, x_test_6, y_test_6 = read_windows(horizon=8)\n",
    "\n",
    "LSTM_model = prepare_model_LSTM(history_length)\n",
    "linear_model = prepare_model_linear(history_length)\n",
    "\n",
    "# NOTE: Be sure that the save_filepath is a real path. If not, the callback\n",
    "#won't save your model and you will lose your progress\n",
    "\n",
    "print(\"########################################################################\")\n",
    "hist = train(x_train_6, y_train_6, LSTM_model, horizon=6, save_filepath=\"LSTM\")\n",
    "print(\"########################################################################\")\n",
    "print()\n",
    "\n",
    "print(\"########################################################################\")\n",
    "hist = train(x_train_8, y_train_8, LSTM_model, horizon=8, save_filepath=\"LSTM\")\n",
    "print(\"########################################################################\")\n",
    "print()\n",
    "\n",
    "print(\"########################################################################\")\n",
    "hist = train(x_train_6, y_train_6, linear_model, horizon=6, save_filepath=\"Linear\")\n",
    "print(\"########################################################################\")\n",
    "print()\n",
    "\n",
    "print(\"########################################################################\")\n",
    "hist = train(x_train_8, y_train_8, linear_model, horizon=8, save_filepath=\"Linear\")\n",
    "print(\"########################################################################\")\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def clarke_error_grid(ref_values, pred_values, title_string, show_plot=True):\n",
    "    \"\"\"\n",
    "      This function takes in the reference values and the prediction values as lists and returns a list with each index corresponding to the total number\n",
    "     of points within that zone (0=A, 1=B, 2=C, 3=D, 4=E) and the plot\n",
    "    \"\"\"\n",
    "    #Checking to see if the lengths of the reference and prediction arrays are the same\n",
    "    assert (len(ref_values) == len(pred_values)), \"Unequal number of values (reference : {0}) (prediction : {1}).\".format(len(ref_values), len(pred_values))\n",
    "\n",
    "    #Checks to see if the values are within the normal physiological range, otherwise it gives a warning\n",
    "    if max(ref_values) > 500 or max(pred_values) > 500:\n",
    "        print(\"Input Warning: the maximum reference value {0} or the maximum prediction value {1} exceeds the normal physiological range of glucose (<400 mg/dl).\".format(max(ref_values), max(pred_values)))\n",
    "    if min(ref_values) < 0 or min(pred_values) < 0:\n",
    "        print( \"Input Warning: the minimum reference value {0} or the minimum prediction value {1} is less than 0 mg/dl.\".format(min(ref_values),  min(pred_values)))\n",
    "\n",
    "    values_out_grid = sum(value > 500 for value in pred_values) + sum(value < 0 for value in pred_values)\n",
    "    print(f\"Number of values outside the grid: {values_out_grid}\")\n",
    "\n",
    "    if show_plot:\n",
    "      #Clear plot\n",
    "      plt.clf()\n",
    "\n",
    "      #Set up plot\n",
    "      plt.scatter(ref_values, pred_values, marker='o', color='black', s=8)\n",
    "      plt.title(title_string + \" Clarke Error Grid\")\n",
    "      plt.xlabel(\"Reference Concentration (mg/dl)\")\n",
    "      plt.ylabel(\"Prediction Concentration (mg/dl)\")\n",
    "      plt.xticks([0, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500])\n",
    "      plt.yticks([0, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500])\n",
    "      plt.gca().set_facecolor('white')\n",
    "\n",
    "      #Set axes lengths\n",
    "      plt.gca().set_xlim([0, 500])\n",
    "      plt.gca().set_ylim([0, 500])\n",
    "      plt.gca().set_aspect((500)/(500))\n",
    "\n",
    "      #Plot zone lines\n",
    "      plt.plot([0,500], [0,500], ':', c='black')                      #Theoretical 45 regression line\n",
    "      plt.plot([0, 175/3], [70, 70], '-', c='black')\n",
    "      #plt.plot([175/3, 320], [70, 500], '-', c='black')\n",
    "      plt.plot([175/3, 500/1.2], [70, 500], '-', c='black')           #Replace 320 with 400/1.2 because 100*(400 - 400/1.2)/(400/1.2) =  20% error\n",
    "      plt.plot([70, 70], [84, 500],'-', c='black')\n",
    "      plt.plot([0, 70], [180, 180], '-', c='black')\n",
    "      plt.plot([70, 290],[180, 500],'-', c='black')\n",
    "      # plt.plot([70, 70], [0, 175/3], '-', c='black')\n",
    "      plt.plot([70, 70], [0, 56], '-', c='black')                     #Replace 175.3 with 56 because 100*abs(56-70)/70) = 20% error\n",
    "      # plt.plot([70, 500],[175/3, 320],'-', c='black')\n",
    "      plt.plot([70, 500], [56, 320],'-', c='black')\n",
    "      plt.plot([180, 180], [0, 70], '-', c='black')\n",
    "      plt.plot([180, 500], [70, 70], '-', c='black')\n",
    "      plt.plot([240, 240], [70, 180],'-', c='black')\n",
    "      plt.plot([240, 500], [180, 180], '-', c='black')\n",
    "      plt.plot([130, 180], [0, 70], '-', c='black')\n",
    "\n",
    "      #Add zone titles\n",
    "      plt.text(30, 15, \"A\", fontsize=15)\n",
    "      plt.text(370, 260, \"B\", fontsize=15)\n",
    "      plt.text(280, 370, \"B\", fontsize=15)\n",
    "      plt.text(160, 370, \"C\", fontsize=15)\n",
    "      plt.text(160, 15, \"C\", fontsize=15)\n",
    "      plt.text(30, 140, \"D\", fontsize=15)\n",
    "      plt.text(370, 120, \"D\", fontsize=15)\n",
    "      plt.text(30, 370, \"E\", fontsize=15)\n",
    "      plt.text(370, 15, \"E\", fontsize=15)\n",
    "\n",
    "    #Statistics from the data\n",
    "    zone = [0] * 5\n",
    "    for i in range(len(ref_values)):\n",
    "        if (ref_values[i] <= 70 and pred_values[i] <= 70) or (pred_values[i] <= 1.2*ref_values[i] and pred_values[i] >= 0.8*ref_values[i]):\n",
    "            zone[0] += 1    #Zone A\n",
    "\n",
    "        elif (ref_values[i] >= 180 and pred_values[i] <= 70) or (ref_values[i] <= 70 and pred_values[i] >= 180):\n",
    "            zone[4] += 1    #Zone E\n",
    "\n",
    "        elif ((ref_values[i] >= 70 and ref_values[i] <= 290) and pred_values[i] >= ref_values[i] + 110) or ((ref_values[i] >= 130 and ref_values[i] <= 180) and (pred_values[i] <= (7/5)*ref_values[i] - 182)):\n",
    "            zone[2] += 1    #Zone C\n",
    "        elif (ref_values[i] >= 240 and (pred_values[i] >= 70 and pred_values[i] <= 180)) or (ref_values[i] <= 175/3 and pred_values[i] <= 180 and pred_values[i] >= 70) or ((ref_values[i] >= 175/3 and ref_values[i] <= 70) and pred_values[i] >= (6/5)*ref_values[i]):\n",
    "            zone[3] += 1    #Zone D\n",
    "        else:\n",
    "            zone[1] += 1    #Zone B\n",
    "\n",
    "    return zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values_per_zone(values):\n",
    "  keys = ['A', 'B', 'C', 'D', 'E']\n",
    "  return {key: value for key, value in zip(keys, values)}\n",
    "\n",
    "def show_results(model, x_test, y_test):\n",
    "\n",
    "  \n",
    "  test_score = model.evaluate(x_test, y_test)\n",
    "  print(f\"RMSE: {test_score[1]}\")\n",
    "  print()\n",
    "\n",
    "  #PREDICTION\n",
    "  print(\"########################################################################\")\n",
    "  print(\"Predicting BG values...\")\n",
    "  BG_predicted_values = model.predict(x_test)\n",
    "  print(\"########################################################################\")\n",
    "  print()\n",
    "\n",
    "  # Clarke error grid\n",
    "  values = clarke_error_grid(y_test, BG_predicted_values, f\"Clarke Error Grid\", show_plot=True)\n",
    "\n",
    "\n",
    "  values_zones = get_values_per_zone(values)\n",
    "  predicted_values_len = y_test.shape[0]\n",
    "  perc_values_zones = [value / predicted_values_len * 100 for value in values_zones.values()]\n",
    "\n",
    "  perc_values_zones = get_values_per_zone(perc_values_zones)\n",
    "\n",
    "  return test_score, perc_values_zones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model = prepare_model_LSTM(history_length, weights=\"LSTM6\")    #En weights ir√≠an los pesos calculados en el train\n",
    "x_train_6, y_train_6, x_test_6, y_test_6 = read_windows(horizon=6)\n",
    "show_results(LSTM_model, x_test_6, y_test_6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
